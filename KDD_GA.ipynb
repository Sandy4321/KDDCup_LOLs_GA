{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/slremy/netsapi\n",
      "  Cloning https://github.com/slremy/netsapi to c:\\users\\admin\\appdata\\local\\temp\\pip-req-build-b00guu7f\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/slremy/netsapi 'C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-req-build-b00guu7f'\n",
      "    ERROR: Complete output from command python setup.py egg_info:\n",
      "    ERROR: Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"d:\\devapps\\python3.6.5\\lib\\tokenize.py\", line 452, in open\n",
      "        buffer = _builtin_open(filename, 'rb')\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Temp\\\\pip-req-build-b00guu7f\\\\setup.py'\n",
      "    ----------------------------------------\n",
      "ERROR: Command \"python setup.py egg_info\" failed with error code 1 in C:\\Users\\ADMIN\\AppData\\Local\\Temp\\pip-req-build-b00guu7f\\\n",
      "WARNING: You are using pip version 19.1.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "from sys import exit, exc_info, argv\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import UtilityFunction\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib import mlab\n",
    "from matplotlib import gridspec\n",
    "import pandas as pd\n",
    "\n",
    "!pip3 install git+https://github.com/slremy/netsapi --user --upgrade\n",
    "\n",
    "from netsapi.challenge import *\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            \n",
    "import statistics\n",
    "from IPython.display import clear_output\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105  Evaluations Remaining\n",
      "104  Evaluations Remaining\n",
      "103  Evaluations Remaining\n",
      "102  Evaluations Remaining\n",
      "101  Evaluations Remaining\n",
      "100  Evaluations Remaining\n",
      "99  Evaluations Remaining\n",
      "98  Evaluations Remaining\n",
      "97  Evaluations Remaining\n",
      "96  Evaluations Remaining\n",
      "95  Evaluations Remaining\n",
      "94  Evaluations Remaining\n",
      "93  Evaluations Remaining\n",
      "92  Evaluations Remaining\n",
      "91  Evaluations Remaining\n",
      "90  Evaluations Remaining\n",
      "final:  [[0.4, 1.0], [0.3, 1.0], [0.19999999999999998, 1.0], [0.4, 0.9], [0.19999999999999998, 0.9], [0.4, 0.8], [0.3, 0.8], [0.19999999999999998, 0.8]]\n",
      "89  Evaluations Remaining\n",
      "88  Evaluations Remaining\n",
      "87  Evaluations Remaining\n",
      "final:  [[0.4, 1.0], [0.19999999999999998, 1.0], [0.19999999999999998, 0.9], [0.4, 0.8], [0.19999999999999998, 0.8]]\n",
      "86  Evaluations Remaining\n"
     ]
    }
   ],
   "source": [
    "#### TRICK HERE ####\n",
    "# SEARCH FOR MAX REWARD OF YEAR 1 THEN APPLY GA ON THE REMAINING YEARS\n",
    "# Search max year 1 \n",
    "def actionSpace(resolution):\n",
    "    x,y = np.meshgrid(np.arange(0,1.1,resolution), np.arange(0,1.1,resolution))\n",
    "    xy = np.concatenate((x.reshape(-1,1), y.reshape(-1,1)), axis=1)\n",
    "    return xy.round(2).tolist()\n",
    "\n",
    "def exploitSpace(action,resolution):\n",
    "    cactionspace = []\n",
    "    final = []\n",
    "    for i in [resolution,0,-resolution]:\n",
    "        for j in [resolution,0,-resolution]:\n",
    "            cactionspace.append([action[0]+j,action[1]+i])\n",
    "    for a in cactionspace:\n",
    "        if(a not in memory and a[0]<=1 and a[0]>=0 and a[1]<=1 and a[1]>=0):\n",
    "            final.append(a)\n",
    "    print(\"final: \", final)\n",
    "    return final\n",
    "\n",
    "action_resolution_year1 = 0.3\n",
    "actionyear1 = actionSpace(action_resolution_year1)\n",
    "actionspaceyear1 = range(len(actionyear1)-1)\n",
    "memory = []\n",
    "action_resolution = 0.1\n",
    "maxactionyear1 = []\n",
    "rewardmaxyear1 = -9999\n",
    "count = 20\n",
    "\n",
    "# ChallengeSeqDecEnvironment = environment 1 (Old Environment)\n",
    "# ChallengeProveEnvironment = environment 2 (New Environment)\n",
    "\n",
    "env = ChallengeProveEnvironment()\n",
    "# env = ChallengeSeqDecEnvironment()\n",
    "\n",
    "for a in actionyear1:\n",
    "            \n",
    "    tempa = a\n",
    "    count-=1\n",
    "    env.reset()\n",
    "    _,reward,_,_ = env.evaluateAction(tempa);\n",
    "    memory.append(tempa)\n",
    "    if(reward > rewardmaxyear1):\n",
    "        rewardmaxyear1 = reward\n",
    "        maxactionyear1 = tempa\n",
    "\n",
    "spaceExploit = exploitSpace(maxactionyear1, action_resolution)\n",
    "\n",
    "while(count>0):\n",
    "    env.reset()\n",
    "    nextaction = []\n",
    "    direct = 0\n",
    "    if(direct == 1):\n",
    "        actionchoice = nextaction\n",
    "    else:\n",
    "        actionchoice = random.choice(spaceExploit)\n",
    "    if(actionchoice not in memory):\n",
    "        env.reset()\n",
    "        _,reward,_,_ = env.evaluateAction(actionchoice)\n",
    "        count-=1\n",
    "        memory.append(actionchoice)\n",
    "        direction = [actionchoice[0] - maxactionyear1[0],actionchoice[1] - maxactionyear1[1]]\n",
    "        if(reward > rewardmaxyear1):\n",
    "            rewardmaxyear1 = reward\n",
    "            maxactionyear1 = actionchoice\n",
    "            nextaction = [actionchoice[0] + direction[0],actionchoice[1] + direction[1]]\n",
    "            direct =1\n",
    "            if(nextaction[0] >1 or nextaction[0] <0 or nextaction[1] >1 or nextaction[1] <0):\n",
    "                nextaction = [actionchoice[0] - direction[0],actionchoice[1] - direction[1]]\n",
    "                spaceExploit = exploitSpace(nextaction, action_resolution)\n",
    "                direct = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "code_folding": [
     39
    ]
   },
   "outputs": [],
   "source": [
    "class CustomAgent:\n",
    "    def __init__(self, environment=1, episode_number=1):\n",
    "        if environment == 1:\n",
    "            self.environment = ChallengeSeqDecEnvironment()\n",
    "        else:\n",
    "            self.environment = ChallengeProveEnvironment()\n",
    "        self.episode_number = episode_number\n",
    "\n",
    "        self.run = []\n",
    "        self.scores = []\n",
    "        self.policies = []\n",
    "        self.seed = {'1': [0.0, 0.8], '2': [1.0, 0.0], '3': [0.1, 0.8], '4': [1.0, 0.0], '5': [0.2, 0.8]}\n",
    "        \n",
    "    def evaluateAPolicy(self, individualPolicy):\n",
    "        self.environment.reset()\n",
    "        rewards = self.environment.evaluatePolicy(individualPolicy)\n",
    "        print(\"Policy\", individualPolicy, \"yields reward\", rewards)\n",
    "        \n",
    "    def my_generate(self, randomGeneration):\n",
    "        try:\n",
    "            self.environment.reset()\n",
    "            # number of 1st policies\n",
    "            n1stEp = 20\n",
    "            # number of new policies to be created\n",
    "            nNew = 180\n",
    "#             # Generate randomly 20 policies - 1st generation\n",
    "#             policies = []\n",
    "#             for i in range(n1stEp):\n",
    "#                 policy = {}\n",
    "#                 for j in range(5): # 5 years\n",
    "#                     policy[str(j + 1)] = [random.random(), random.random()]\n",
    "#                 policies.append(policy)    \n",
    "\n",
    "            # 26.06.19 Generate 1st gen based on seed\n",
    "            policies = []\n",
    "            for i in range(n1stEp):\n",
    "                policy = {}\n",
    "                for j in range(5):\n",
    "                    feature1 = random.random() + self.seed[str(j + 1)][0]\n",
    "                    feature2 = random.random() + self.seed[str(j + 1)][1]\n",
    "                    if feature1 < 0.0:\n",
    "                        feature1 = 0.0\n",
    "                    elif feature1 > 1.0:\n",
    "                        feature1 = 1.0\n",
    "                    if feature2 < 0.0:\n",
    "                        feature2 = 0.0\n",
    "                    elif feature2 > 1.0:\n",
    "                        feature1 = 1.0    \n",
    "                    policy[str(j + 1)] = [feature1, feature2]\n",
    "\n",
    "            rewards = self.environment.evaluatePolicy(policies)\n",
    "#             print(\"1st gen policies length: \", len(policies))\n",
    "#             print(\"1st gen rewards length: \", len(rewards))\n",
    "\n",
    "            for episode in range(nNew):\n",
    "#                 print(\"Episode \", episode)\n",
    "                newPolicy, newReward = self.roulette_wheel_selection(policies, rewards)\n",
    "                policies.append(newPolicy)\n",
    "                rewards.append(newReward)            \n",
    "        except (KeyboardInterrupt, SystemExit, ValueError):\n",
    "            print(exc_info())\n",
    "        return policies[np.argmax(rewards)], rewards[np.argmax(rewards)]\n",
    "\n",
    "    def roulette_wheel_selection(self, current_policies, current_rewards, noise1=0.0, noise2=0.0):\n",
    "        maxR = np.max(current_rewards)\n",
    "        minR = np.min(current_rewards)\n",
    "        fitness = []\n",
    "        for reward in current_rewards:\n",
    "            normalized = (reward - minR) / (maxR - minR)\n",
    "            fitness.append(normalized * (-1.0))\n",
    "        \n",
    "        sumFitness = np.sum(fitness)\n",
    "        p = []\n",
    "        for f in fitness:\n",
    "            p.append(f / sumFitness)\n",
    "            \n",
    "        # sort policies, rewards, fitness, probabilities based on probability\n",
    "        for i in range(len(p) - 1):\n",
    "            for j in range(i + 1, len(p)):\n",
    "                if p[i] > p[j]:\n",
    "                    # swap prob\n",
    "                    temp = p[i]\n",
    "                    p[i] = p[j]\n",
    "                    p[j] = temp\n",
    "                    \n",
    "                    # swap policies\n",
    "                    temp = current_policies[i]\n",
    "                    current_policies[i] = current_policies[j]\n",
    "                    current_policies[j] = temp\n",
    "                    \n",
    "                    # swap rewards\n",
    "                    temp= current_rewards[i]\n",
    "                    current_rewards[i] = current_rewards[j]\n",
    "                    current_rewards[j] = temp\n",
    "                    \n",
    "                    # swap fitness\n",
    "                    temp = fitness[i]\n",
    "                    fitness[i] = fitness[j]\n",
    "                    fitness[j] = temp\n",
    "                    \n",
    "        # choose 2 policies from the set\n",
    "        chosenPolicies = []\n",
    "        chosenIndex = -1\n",
    "#         for chosenI in range(2):\n",
    "        while len(chosenPolicies) < 2:\n",
    "            randomSelection = np.random.uniform(p[0], p[len(p)-1])\n",
    "            for index, pi in enumerate(p):\n",
    "                if randomSelection < pi and chosenIndex != index:\n",
    "                    chosenPolicies.append(current_policies[index])\n",
    "                    chosenIndex = index\n",
    "                    break\n",
    "        # Create new policy by mixing the 2 chosen policies\n",
    "        newPolicy = {}\n",
    "        for i in range(0, 5):    # 5 years (states)\n",
    "            chosen = 0\n",
    "            if np.random.uniform(0, 1) > 0.5:\n",
    "                chosen = 1\n",
    "            newPolicy[str(i + 1)] = chosenPolicies[chosen][str(i + 1)]\n",
    "            \n",
    "            # then add noise into them\n",
    "            newPolicy[str(i + 1)][0] += noise1\n",
    "            newPolicy[str(i + 1)][1] += noise2\n",
    "            \n",
    "            if newPolicy[str(i + 1)][0] > 1.0:\n",
    "                newPolicy[str(i + 1)][0] = 1.0\n",
    "            if newPolicy[str(i + 1)][0] < 0.0:\n",
    "                newPolicy[str(i + 1)][0] = 0.0\n",
    "            if newPolicy[str(i + 1)][1] > 1.0:\n",
    "                newPolicy[str(i + 1)][1] = 1.0\n",
    "            if newPolicy[str(i + 1)][1] < 0.0:\n",
    "                newPolicy[str(i + 1)][1] = 0.0\n",
    "        newPolicy['1'] = copy.deepcopy(maxactionyear1)    #### TRICK HERE ####\n",
    "        \n",
    "        # new reward\n",
    "        newReward = self.environment.evaluatePolicy(newPolicy)\n",
    "        return newPolicy, newReward\n",
    "        \n",
    "    def scoringFunction(self):\n",
    "        scores = []\n",
    "        for ii in range(1):\n",
    "#             print(\"Run #\", ii)\n",
    "            self.environment.reset()\n",
    "            finalresult, reward = self.my_generate()\n",
    "            self.policies.append(finalresult)\n",
    "            self.scores.append(reward)\n",
    "            self.run.append(ii)\n",
    "#         print(\"Length: \", len(self.scores))\n",
    "        return np.mean(self.scores)/np.std(self.scores)\n",
    " \n",
    "        \n",
    "    def create_submissions(self, filename = 'my_submission.csv'):\n",
    "        labels = ['run', 'reward', 'policy']\n",
    "        rewards = np.array(self.scores)\n",
    "        data = { 'run': self.run, \n",
    "                 'rewards': rewards,\n",
    "                 'policy': self.policies,\n",
    "               }\n",
    "        submission_file = pd.DataFrame(data)\n",
    "        submission_file.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== START RUN # 1  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.935223049996954, 0.9621210364858436], '3': [0.609489018187597, 0.2539222594620282], '4': [0.9265680530727578, 0.11802032084173186], '5': [0.8509572757476047, 0.4702599224427454]}, {'1': [0.19999999999999998, 0.9], '2': [0.8800989385475777, 0.45740541635119847], '3': [0.7729827665533537, 0.07559780967726892], '4': [0.31583677137171984, 0.669430717491807], '5': [0.5836236605060183, 0.20689986839711838]}, {'1': [0.19999999999999998, 0.9], '2': [0.05493321148774588, 0.9865114406469137], '3': [0.1710086401345945, 0.6539163302195657], '4': [0.6990891997780653, 0.967251077370552], '5': [0.8351146621140778, 0.8056362747956396]}, {'1': [0.19999999999999998, 0.9], '2': [0.8258938020772829, 0.24216172481413467], '3': [0.4096158688158078, 0.8348230976711005], '4': [0.05996088980153791, 0.08795665184745516], '5': [0.16596496875041822, 0.668444362414795]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  347.03242612847697\n",
      "=== START RUN # 2  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.6093318598623314, 0.7457306509828469], '3': [0.43689649680562215, 0.8928906556590243], '4': [0.148106137888257, 0.7191954576713675], '5': [0.6920980558786931, 0.19105268825686783]}, {'1': [0.19999999999999998, 0.9], '2': [0.6626602695662709, 0.2882259908890883], '3': [0.3253365197430067, 0.8310130078559533], '4': [0.5983866074005942, 0.7491701307574451], '5': [0.5474300220674847, 0.9344408349716287]}, {'1': [0.19999999999999998, 0.9], '2': [0.9827495426021613, 0.3592305937468665], '3': [0.8317549061674923, 0.7336714585986933], '4': [0.3397313954097585, 0.6067887383306307], '5': [0.49541927632144656, 0.6341049873334608]}, {'1': [0.19999999999999998, 0.9], '2': [0.3009072699535631, 0.7977945276050532], '3': [0.8290366193143636, 0.6714057251262846], '4': [0.15147611782398673, 0.8116055716753875], '5': [0.926634188178051, 0.8249291510875708]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  350.3464561466396\n",
      "=== START RUN # 3  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.34882461307995305, 0.43610534603752493], '3': [0.23315396643571218, 0.9486856154585005], '4': [0.4806787813228516, 0.9018307664826223], '5': [0.2582041056600143, 0.12937518133486037]}, {'1': [0.19999999999999998, 0.9], '2': [0.9781862416434264, 0.7826437207236526], '3': [0.5250660225579309, 0.7304566556757024], '4': [0.7650446304704708, 0.6724762840911029], '5': [0.9208618173313549, 0.6757728428975455]}, {'1': [0.19999999999999998, 0.9], '2': [0.16563043185718673, 0.11981823034608086], '3': [0.5096144278573456, 0.4205553380576984], '4': [0.3422040196273547, 0.6708790926298038], '5': [0.299114809209053, 0.6023310038123353]}, {'1': [0.19999999999999998, 0.9], '2': [0.951273295377344, 0.26105579712522353], '3': [0.5148079853392283, 0.9580234476897213], '4': [0.9150028466471986, 0.03559468273327526], '5': [0.8675714737795688, 0.1876201824539412]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  342.9497141917654\n",
      "=== START RUN # 4  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.8361326584430793, 0.7640098821467906], '3': [0.7226720654735116, 0.26029141209699125], '4': [0.5790484860829276, 0.6528331096637833], '5': [0.27228319751291985, 0.8113662153781824]}, {'1': [0.19999999999999998, 0.9], '2': [0.3569166727420555, 0.14734061571403845], '3': [0.7923374673406132, 0.6929926677785394], '4': [0.10150567656171683, 0.40995491785065175], '5': [0.39318332746795115, 0.31566269446088535]}, {'1': [0.19999999999999998, 0.9], '2': [0.24257979402316343, 0.07276277643310736], '3': [0.2808967671581276, 0.5210753601735538], '4': [0.8658190439592536, 0.5312672408115697], '5': [0.8226953492104158, 0.851027207933439]}, {'1': [0.19999999999999998, 0.9], '2': [0.7118146432669752, 0.2604820683487543], '3': [0.5207537974225125, 0.6663188847220751], '4': [0.8077683422638539, 0.33429915773011765], '5': [0.44647898192807844, 0.879247030938877]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  341.6874826805697\n",
      "=== START RUN # 5  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.8328450829838502, 0.2067268197006803], '3': [0.10258499136776233, 0.19143479928242813], '4': [0.8237569666206374, 0.20319642690700945], '5': [0.7612370669857, 0.8405827153837262]}, {'1': [0.19999999999999998, 0.9], '2': [0.9767295453833319, 0.22963618124429386], '3': [0.9657462281592466, 0.2894802738276657], '4': [0.07279472001005849, 0.9938539710208462], '5': [0.4161412877563052, 0.6482527179939633]}, {'1': [0.19999999999999998, 0.9], '2': [0.5616372032105262, 0.40419615505914874], '3': [0.8940549625002131, 0.6103424812198592], '4': [0.42536643603999735, 0.691317200703172], '5': [0.5593297476626323, 0.5908877774263914]}, {'1': [0.19999999999999998, 0.9], '2': [0.31425629603133354, 0.9516313136060561], '3': [0.07734651536118753, 0.6378750084503528], '4': [0.5654748321640269, 0.8826621803779042], '5': [0.24350135246784865, 0.6490751987186889]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  369.42171496105175\n",
      "=== START RUN # 6  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.581302366232209, 0.5707925344518084], '3': [0.33105466440854525, 0.5600276211874419], '4': [0.7520420519297086, 0.6041283229008741], '5': [0.9225530372193377, 0.5498562380356429]}, {'1': [0.19999999999999998, 0.9], '2': [0.03317610046594743, 0.7779390258340196], '3': [0.33472985495778995, 0.20264956272639356], '4': [0.24478410229995373, 0.11669278722945453], '5': [0.11159109224532093, 0.18053888695456777]}, {'1': [0.19999999999999998, 0.9], '2': [0.7556782215443147, 0.7748349922752017], '3': [0.5895233080801219, 0.6801857755087243], '4': [0.5681506124494927, 0.6707620859141683], '5': [0.16245057213630565, 0.2871831773939968]}, {'1': [0.19999999999999998, 0.9], '2': [0.8244761032930147, 0.22340208948261298], '3': [0.03578870302439974, 0.2995327773864972], '4': [0.38079531667530786, 0.6622440545046907], '5': [0.585243905515638, 0.079150602717456]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  367.97067214066374\n",
      "=== START RUN # 7  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.4659842072716772, 0.6412788638606126], '3': [0.9881560680742022, 0.16935533855078433], '4': [0.9860730661753544, 0.46027973331063865], '5': [0.5908749197221863, 0.7678151878274007]}, {'1': [0.19999999999999998, 0.9], '2': [0.15368769241050662, 0.18911195452327112], '3': [0.022503591567725634, 0.3007780488186329], '4': [0.3024509104308263, 0.25342160074046893], '5': [0.8113468292813047, 0.2717022116342134]}, {'1': [0.19999999999999998, 0.9], '2': [0.6704508371351107, 0.5123031729886997], '3': [0.6985435058036469, 0.8152828374351369], '4': [0.6656625767135994, 0.40729039904420516], '5': [0.8695569321690355, 0.30431973824787106]}, {'1': [0.19999999999999998, 0.9], '2': [0.8020346951388274, 0.4952153268233521], '3': [0.45112569786065226, 0.8243062591376968], '4': [0.76462275840896, 0.7665279248933331], '5': [0.8616025098379795, 0.5958618951402559]}]\n",
      "105  Evaluations Remaining\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  343.40199151494704\n",
      "=== START RUN # 8  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.4226356791973803, 0.8545158521512757], '3': [0.8069333377964398, 0.6474185291622193], '4': [0.7921084087028929, 0.47493713100191937], '5': [0.2086328175162383, 0.12390111496040801]}, {'1': [0.19999999999999998, 0.9], '2': [0.3069322867775387, 0.8049033716789713], '3': [0.7466409095488511, 0.731742827926638], '4': [0.05320418514304592, 0.4790264480670605], '5': [0.8061989713531929, 0.13585218667295407]}, {'1': [0.19999999999999998, 0.9], '2': [0.09842949355160546, 0.5270529101399931], '3': [0.3029619855843062, 0.959147889610902], '4': [0.5638396743354275, 0.004067032650868385], '5': [0.5017441517246364, 0.46292470244525474]}, {'1': [0.19999999999999998, 0.9], '2': [0.8695806655086077, 0.5790918587345908], '3': [0.6131449812524272, 0.45287797087512516], '4': [0.9808330378919774, 0.1827584980715995], '5': [0.27917614359264087, 0.6720860259806709]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  350.84768076477064\n",
      "=== START RUN # 9  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.271317578209072, 0.18440769950609004], '3': [0.06529394215194606, 0.9474081745648925], '4': [0.5304241340795631, 0.3960318579566968], '5': [0.23452111170696288, 0.26339060210960197]}, {'1': [0.19999999999999998, 0.9], '2': [0.8673015381725325, 0.8393567329920083], '3': [0.015832554455570635, 0.26707324565379165], '4': [0.3748357855966049, 0.7786059955416832], '5': [0.1105208840104116, 0.800522415471735]}, {'1': [0.19999999999999998, 0.9], '2': [0.26755002503122327, 0.8992413493974242], '3': [0.2958145599874167, 0.460331537241328], '4': [0.7935555761671794, 0.7612097284850764], '5': [0.9821850244041956, 0.6163859561040415]}, {'1': [0.19999999999999998, 0.9], '2': [0.4193303358863877, 0.17191786158772338], '3': [0.646729479114094, 0.24287178296448408], '4': [0.08846473533871035, 0.13907762480632224], '5': [0.3341568080479782, 0.7673284213425806]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  400.01575511847557\n",
      "=== START RUN # 10  /  10  ON ENVIRONMENT  2  ===\n",
      "1st generation: [{'1': [0.19999999999999998, 0.9], '2': [0.4705663788223564, 0.7023432042930898], '3': [0.63955914086021, 0.40161767231881873], '4': [0.8015684598171333, 0.5990823357224696], '5': [0.8289388926980072, 0.44628555988573637]}, {'1': [0.19999999999999998, 0.9], '2': [0.14192352394304886, 0.33644253209398567], '3': [0.6184840643302645, 0.1838199664728143], '4': [0.722397746637423, 0.562040242946338], '5': [0.36623365779682016, 0.43452460666514325]}, {'1': [0.19999999999999998, 0.9], '2': [0.568050347229348, 0.17494071286670232], '3': [0.42871950232783596, 0.9355029687736061], '4': [0.08599714117108925, 0.9981161757394484], '5': [0.9694703407801464, 0.7918476214851198]}, {'1': [0.19999999999999998, 0.9], '2': [0.05714974918446536, 0.33862650298646424], '3': [0.12591631904571166, 0.39236803622217464], '4': [0.7930303034881484, 0.08159643736285505], '5': [0.185910899500786, 0.5744932379377229]}]\n",
      "105  Evaluations Remaining\n",
      "85  Evaluations Remaining\n",
      "80  Evaluations Remaining\n",
      "75  Evaluations Remaining\n",
      "70  Evaluations Remaining\n",
      "65  Evaluations Remaining\n",
      "60  Evaluations Remaining\n",
      "55  Evaluations Remaining\n",
      "50  Evaluations Remaining\n",
      "45  Evaluations Remaining\n",
      "40  Evaluations Remaining\n",
      "35  Evaluations Remaining\n",
      "30  Evaluations Remaining\n",
      "Max rewards:  403.2715640008605\n"
     ]
    }
   ],
   "source": [
    "numOfRun = 10 ########### NUM OF RUNS ############\n",
    "rewardsRun = []\n",
    "evolutionReward = []\n",
    "useEnvironment = 2\n",
    "# Generate randomly 5 policies - 1st generation\n",
    "noises = np.linspace(0.05, 0.95, 21)\n",
    "for run in range(numOfRun):\n",
    "    print(\"=== START RUN #\", run + 1, \" / \", numOfRun, \" ON ENVIRONMENT \", useEnvironment, \" ===\")\n",
    "    entityCnt = 0\n",
    "    firstGeneration = []\n",
    "    run = []\n",
    "    evolutionReward = []\n",
    "    agent = CustomAgent(environment=useEnvironment)\n",
    "    # each policy costs 5 evaluations, so firstPopulation * 5 evaluations, 105 = 21 run\n",
    "    numOfFirstPopulation = 4       # change here\n",
    "    for i in range(numOfFirstPopulation):\n",
    "        policy = {}\n",
    "        run.append(i)\n",
    "        for j in range(5): # 5 years\n",
    "            policy[str(j + 1)] = [np.random.uniform(0.0, 1.0), np.random.uniform(0.0, 1.0)]\n",
    "        policy['1'] = copy.deepcopy(maxactionyear1)   #### TRICK HERE ####\n",
    "        firstGeneration.append(policy)    \n",
    "        entityCnt = entityCnt + 1\n",
    "    \n",
    "    # 1st gen\n",
    "    print(\"1st generation:\", firstGeneration)\n",
    "    firstGenRewards = agent.environment.evaluatePolicy(firstGeneration)\n",
    "    evolutionReward = firstGenRewards.copy()\n",
    "\n",
    "    # Generate new 10000 policies based on GA\n",
    "    numOfExpoitedPopulation = (80 - numOfFirstPopulation * 5) / 5\n",
    "    for i in range(int(numOfExpoitedPopulation)):\n",
    "        run.append(i)\n",
    "        newPolicy, newReward = agent.roulette_wheel_selection(firstGeneration, firstGenRewards, noises[entityCnt], noises[entityCnt])\n",
    "        firstGeneration.append(newPolicy)\n",
    "        firstGenRewards.append(newReward)\n",
    "        evolutionReward.append(newReward)\n",
    "        entityCnt = entityCnt + 1\n",
    "\n",
    "    # Write file\n",
    "    labels = ['run', 'reward', 'policy']\n",
    "    data = { 'run': run, \n",
    "             'rewards': firstGenRewards,\n",
    "             'policy': firstGeneration,\n",
    "           }\n",
    "    # submission_file = pd.DataFrame(data)\n",
    "    # submission_file.to_csv(\"result.csv\", index=False)\n",
    "    print(\"Max rewards: \", np.max(data['rewards']))\n",
    "\n",
    "    rewardsRun.append(np.max(data['rewards']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(\"firstGenRewards\", firstGenRewards)\n",
    "# print(\"evolutionReward\", evolutionReward)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot([i for i in range(0, len(firstGenRewards) - 1)], firstGenRewards[:-1])\n",
    "\n",
    "ax.set(xlabel='Testing #', \n",
    "       ylabel='Reward',\n",
    "       title='Genetic Algorithm')\n",
    "ax.grid()\n",
    "\n",
    "fig.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
